name: Discord Log Auto-Updater

on:
  schedule:
    - cron: '0 */12 * * *' # Runs every 12 hours
  workflow_dispatch:      # Allows manual trigger

jobs:
  update_logs:
    runs-on: ubuntu-latest
    
    steps:
      - name: Setup Tools
        run: |
          curl -L https://github.com/Tyrrrz/DiscordChatExporter/releases/latest/download/DiscordChatExporter.Cli.linux-x64.zip -o dce.zip
          unzip dce.zip -d dce && chmod +x dce/DiscordChatExporter.Cli

      - name: Install Pandas
        run: pip install pandas

      - name: Get Dropbox Token
        id: dropbox_auth
        run: |
          TOKEN=$(curl -s -X POST https://api.dropbox.com/oauth2/token \
            -u "${{ secrets.DROPBOX_APP_KEY }}:${{ secrets.DROPBOX_APP_SECRET }}" \
            -d grant_type=refresh_token \
            -d refresh_token="${{ secrets.DROPBOX_REFRESH_TOKEN }}" | jq -r '.access_token')
          echo "atoken=$TOKEN" >> $GITHUB_OUTPUT


      
      # ... (Steps for Setup, Dependencies, and Auth remain the same) ...

      - name: Download, Merge & Sort (TEST MODE)
        run: |
          # 1. Download your GOOD master file as the base
          curl -L "https://www.dropbox.com/scl/fi/i4kw0bam95d3gfd1cuqq2/bruh_log.csv?rlkey=0gj0uncfia4f991hwsgxjifq6&st=3bjjctrg&dl=1" -o master_history.csv
          
          # 2. Export recent data (Change '7 days ago' here to change the window)
          ./dce/DiscordChatExporter.Cli export \
            -t "${{ secrets.DISCORD_TOKEN }}" \
            -c ${{ secrets.CHANNEL_ID }} \
            -f Csv -o recent_slice.csv \
            --after $(date -d "50 days ago" +%Y-%m-%d)

          # 3. Python Merge Logic
          python3 -c "
          import pandas as pd
          try:
              # 1. Load without assuming headers, treat all as strings
              # If your file HAS a header row, 'header=0' is usually safer.
              # If it has NO header, we use 'header=None'. 
              # Let's try header=0 first since most exports have one.
              h = pd.read_csv('master_history.csv', dtype=str, header=0, low_memory=False)
              a = pd.read_csv('recent_slice.csv', dtype=str, header=0, low_memory=False)
              
              print(f'Original Master Rows: {len(h)}')
              
              # 2. Assign temporary names based on position to ensure alignment
              # Column 0 = ID, Column 2 = Timestamp
              h.columns = [f'col_{i}' for i in range(len(h.columns))]
              a.columns = [f'col_{i}' for i in range(len(a.columns))]

              # 3. Combine
              combined = pd.concat([h, a], ignore_index=True)
              
              # 4. Deduplicate using Column 0 (The Message ID)
              # This prevents the '10k rows' issue because we know exactly where the ID is
              final = combined.drop_duplicates(subset=['col_0'], keep='last')
              
              # 5. Sort by Column 2 (The Timestamp)
              # Using errors='coerce' to skip any rows that might be corrupted
              final['col_2'] = pd.to_datetime(final['col_2'], errors='coerce')
              final = final.sort_values(by='col_2', ascending=True)
              
              # 6. Save back
              final.to_csv('test_output.csv', index=False)
              
              print(f'--- RESULTS ---')
              print(f'Added from Discord: {len(a)}')
              print(f'Final Unique Total: {len(final)}')
              
              if len(final) < len(h):
                  print('!!! WARNING: Count dropped. Check if col_0 is truly the unique ID.')
          except Exception as e:
              import traceback
              traceback.print_exc()
              exit(1)
          "
