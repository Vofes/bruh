name: Discord Log Auto-Updater

on:
  workflow_dispatch:      

jobs:
  update_logs:
    runs-on: ubuntu-latest
    
    steps:
      - name: Setup Tools
        run: |
          curl -L https://github.com/Tyrrrz/DiscordChatExporter/releases/latest/download/DiscordChatExporter.Cli.linux-x64.zip -o dce.zip
          unzip dce.zip -d dce && chmod +x dce/DiscordChatExporter.Cli

      - name: Install Pandas
        run: pip install pandas

      - name: Get Dropbox Token
        id: dropbox_auth
        run: |
          TOKEN=$(curl -s -X POST https://api.dropbox.com/oauth2/token \
            -u "${{ secrets.DROPBOX_APP_KEY }}:${{ secrets.DROPBOX_APP_SECRET }}" \
            -d grant_type=refresh_token \
            -d refresh_token="${{ secrets.DROPBOX_REFRESH_TOKEN }}" | jq -r '.access_token')
          echo "atoken=$TOKEN" >> $GITHUB_OUTPUT

      - name: Download, Merge & Sort
        run: |
          # 1. Download Master using your Secret
          curl -L "${{ secrets.DROPBOXLINK }}" -o master_history.csv
          
          # 2. Export Recent (Last 7 Days)
          ./dce/DiscordChatExporter.Cli export \
            -t "${{ secrets.DISCORD_TOKEN }}" \
            -c ${{ secrets.CHANNEL_ID }} \
            -f Csv -o recent_slice.csv \
            --after $(date -d "50 days ago" +%Y-%m-%d)

          # 3. Positional Merge Logic
          python3 -c "
          import pandas as pd
          try:
              # We treat everything as data (no headers) to prevent 'Column Name' confusion
              h = pd.read_csv('master_history.csv', dtype=str, header=None, low_memory=False)
              a = pd.read_csv('recent_slice.csv', dtype=str, header=None, low_memory=False)
              
              print(f'Master: {len(h)} | New: {len(a)}')

              # Combine
              combined = pd.concat([h, a], ignore_index=True)

              # DEDUPLICATE: We use the Timestamp (Col 2) and Content (Col 3)
              # This is the 'Double Key' that prevents the 10k row limit
              final = combined.drop_duplicates(subset=[2, 3], keep='last')

              # SORT: By Timestamp (Col 2)
              final[2] = pd.to_datetime(final[2], errors='coerce')
              final = final.dropna(subset=[2]) 
              final = final.sort_values(by=2, ascending=True)

              final.to_csv('updated_master.csv', index=False, header=False)
              print(f'Final Clean Count: {len(final)}')
          except Exception as e:
              print(f'Error: {e}')
              exit(1)
          "

      - name: Upload to Dropbox
        run: |
          # This saves a NEW file named 'debug_sync.csv' so we can verify it exists
          curl -X POST https://content.dropboxapi.com/2/files/upload \
            --header "Authorization: Bearer ${{ steps.dropbox_auth.outputs.atoken }}" \
            --header "Dropbox-API-Arg: {\"path\": \"/bruh/bruh_log/debug_sync.csv\",\"mode\": \"overwrite\"}" \
            --header "Content-Type: application/octet-stream" \
            --data-binary @updated_master.csv
